{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "klVC6Fzie8Yg"
      },
      "source": [
        "---\n",
        "description: 'First things first: let''s start with a good model!'\n",
        "---\n",
        "\n",
        "# Models\n",
        "\n",
        "Welcome to the \"**Models**\" tutorial of the \"_From Zero to Hero_\" series. In this notebook we will talk about the features offered by the `models` _Avalanche_ sub-module.\n",
        "\n",
        "### Support for pytorch Modules\n",
        "\n",
        "Every continual learning experiment needs a model to train incrementally. You can use any `torch.nn.Module`, even pretrained models.  The `models` sub-module provides the most commonly used architectures in the CL literature.\n",
        "\n",
        "You can use any model provided in the [Pytorch](https://pytorch.org/) official ecosystem models as well as the ones provided by [pytorchcv](https://pypi.org/project/pytorchcv/)!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLJO1nMPe8Yi",
        "outputId": "675bbe78-f167-40dc-ad1d-345c5ea1c3fe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: avalanche-lib==0.6 in /usr/local/lib/python3.11/dist-packages (0.6.0)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (4.12.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (5.9.5)\n",
            "Requirement already satisfied: gputil in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (1.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (1.6.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (1.26.4)\n",
            "Requirement already satisfied: pytorchcv in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (0.0.73)\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (0.19.6)\n",
            "Requirement already satisfied: tensorboard>=1.15 in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (2.18.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (4.67.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (2.5.1+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (0.20.1+cu124)\n",
            "Requirement already satisfied: torchmetrics in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (1.6.1)\n",
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (5.2.0)\n",
            "Requirement already satisfied: qpsolvers[open_source_solvers] in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (4.4.0)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (0.3.9)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from avalanche-lib==0.6) (24.2)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6) (1.70.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6) (3.7)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6) (4.25.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6) (75.1.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard>=1.15->avalanche-lib==0.6) (3.1.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown->avalanche-lib==0.6) (4.13.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown->avalanche-lib==0.6) (3.17.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown->avalanche-lib==0.6) (2.32.3)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->avalanche-lib==0.6) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->avalanche-lib==0.6) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->avalanche-lib==0.6) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->avalanche-lib==0.6) (1.4.8)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->avalanche-lib==0.6) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->avalanche-lib==0.6) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->avalanche-lib==0.6) (2.8.2)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->avalanche-lib==0.6) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->avalanche-lib==0.6) (3.5.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (3.1.5)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (2024.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->avalanche-lib==0.6) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->avalanche-lib==0.6) (1.3.0)\n",
            "Requirement already satisfied: lightning-utilities>=0.8.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics->avalanche-lib==0.6) (0.12.0)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb->avalanche-lib==0.6) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb->avalanche-lib==0.6) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->avalanche-lib==0.6) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb->avalanche-lib==0.6) (4.3.6)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb->avalanche-lib==0.6) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb->avalanche-lib==0.6) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb->avalanche-lib==0.6) (2.22.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb->avalanche-lib==0.6) (1.3.4)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.6) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->avalanche-lib==0.6) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb->avalanche-lib==0.6) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6) (2025.1.31)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard>=1.15->avalanche-lib==0.6) (3.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown->avalanche-lib==0.6) (2.6)\n",
            "Requirement already satisfied: clarabel>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (0.10.0)\n",
            "Requirement already satisfied: cvxopt>=1.2.6 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (1.3.2)\n",
            "Requirement already satisfied: daqp>=0.5.1 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (0.6.0)\n",
            "Requirement already satisfied: ecos>=2.0.8 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (2.0.14)\n",
            "Requirement already satisfied: highspy>=1.1.2.dev3 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (1.9.0)\n",
            "Requirement already satisfied: osqp>=0.6.2 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (0.6.7.post3)\n",
            "Requirement already satisfied: piqp>=0.2.2 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (0.4.2)\n",
            "Requirement already satisfied: proxsuite>=0.2.9 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (0.7.1)\n",
            "Requirement already satisfied: qpalm>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (1.2.5)\n",
            "Requirement already satisfied: qpax>=0.0.9 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (0.0.9)\n",
            "Requirement already satisfied: quadprog>=0.1.11 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (0.1.13)\n",
            "Requirement already satisfied: scs>=3.2.0 in /usr/local/lib/python3.11/dist-packages (from qpsolvers[open_source_solvers]->avalanche-lib==0.6) (3.2.7.post2)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown->avalanche-lib==0.6) (1.7.1)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->avalanche-lib==0.6) (5.0.2)\n",
            "Requirement already satisfied: qdldl in /usr/local/lib/python3.11/dist-packages (from osqp>=0.6.2->qpsolvers[open_source_solvers]->avalanche-lib==0.6) (0.1.7.post5)\n",
            "Requirement already satisfied: cmeel in /usr/local/lib/python3.11/dist-packages (from proxsuite>=0.2.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6) (0.57.1)\n",
            "Requirement already satisfied: jax>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from qpax>=0.0.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6) (0.4.33)\n",
            "Requirement already satisfied: jaxlib>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from qpax>=0.0.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6) (0.4.33)\n",
            "Requirement already satisfied: ml-dtypes>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.0->qpax>=0.0.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6) (0.4.1)\n",
            "Requirement already satisfied: opt-einsum in /usr/local/lib/python3.11/dist-packages (from jax>=0.4.0->qpax>=0.0.9->qpsolvers[open_source_solvers]->avalanche-lib==0.6) (3.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install avalanche-lib==0.6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsTr13Sue8Yi",
        "outputId": "0b0e9a6b-1a32-4980-86de-cbc26edb0f29"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Dropout(p=0.25, inplace=False)\n",
            "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): Dropout(p=0.25, inplace=False)\n",
            "    (12): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): AdaptiveMaxPool2d(output_size=1)\n",
            "    (15): Dropout(p=0.25, inplace=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from avalanche.models import SimpleCNN\n",
        "from avalanche.models import SimpleMLP\n",
        "from avalanche.models import SimpleMLP_TinyImageNet\n",
        "from avalanche.models import MobilenetV1\n",
        "\n",
        "model = SimpleCNN()\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NllV2Gawe8Yj"
      },
      "source": [
        "## Dynamic Model Expansion\n",
        "A continual learning model may change over time. As an example, a classifier may add new units for previously unseen classes, while progressive networks add a new set units after each experience. Avalanche provides `DynamicModule`s to support these use cases. `DynamicModule`s are `torch.nn.Module`s that provide an addition method, `adaptation`, that is used to update the model's architecture. The method takes a single argument, the data from the current experience.\n",
        "\n",
        "For example, an IncrementalClassifier updates the number of output units:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AzlemuBWe8Yj",
        "outputId": "22de6302-e113-43e4-db11-163e6195ae6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9.91M/9.91M [00:00<00:00, 54.5MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.avalanche/data/mnist/MNIST/raw/train-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 28.9k/28.9k [00:00<00:00, 1.89MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.avalanche/data/mnist/MNIST/raw/train-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1.65M/1.65M [00:00<00:00, 14.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.avalanche/data/mnist/MNIST/raw/t10k-images-idx3-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 404: Not Found\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4.54k/4.54k [00:00<00:00, 4.65MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /root/.avalanche/data/mnist/MNIST/raw/t10k-labels-idx1-ubyte.gz to /root/.avalanche/data/mnist/MNIST/raw\n",
            "\n",
            "IncrementalClassifier(\n",
            "  (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            ")\n",
            "IncrementalClassifier(\n",
            "  (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            ")\n",
            "IncrementalClassifier(\n",
            "  (classifier): Linear(in_features=784, out_features=4, bias=True)\n",
            ")\n",
            "IncrementalClassifier(\n",
            "  (classifier): Linear(in_features=784, out_features=6, bias=True)\n",
            ")\n",
            "IncrementalClassifier(\n",
            "  (classifier): Linear(in_features=784, out_features=8, bias=True)\n",
            ")\n",
            "IncrementalClassifier(\n",
            "  (classifier): Linear(in_features=784, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from avalanche.benchmarks import SplitMNIST\n",
        "from avalanche.models import IncrementalClassifier\n",
        "\n",
        "benchmark = SplitMNIST(5, shuffle=False, class_ids_from_zero_in_each_exp=False)\n",
        "model = IncrementalClassifier(in_features=784)\n",
        "\n",
        "print(model)\n",
        "for exp in benchmark.train_stream:\n",
        "    model.adaptation(exp)\n",
        "    print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "gdx9jdv1e8Yj"
      },
      "source": [
        "As you can see, after each call to the `adaptation` method, the model adds 2 new units to account for the new classes. Notice that no learning occurs at this point since the method only modifies the model's architecture.\n",
        "\n",
        "Keep in mind that when you use Avalanche strategies you don't have to call the adaptation yourself. Avalanche strategies automatically call the model's adaptation and update the optimizer to include the new parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "uQPq871me8Yj"
      },
      "source": [
        "## Multi-Task models\n",
        "\n",
        "Some models, such as multi-head classifiers, are designed to exploit task labels. In Avalanche, such models are implemented as `MultiTaskModule`s. These are dynamic models (since they need to be updated whenever they encounter a new task) that have an additional `task_labels` argument in their `forward` method. `task_labels` is a tensor with a task id for each sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yWLR78ge8Yj",
        "outputId": "13a683b0-448a-4e90-ce4c-c3533a84120c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiHeadClassifier(\n",
            "  (classifiers): ModuleDict(\n",
            "    (0): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "MultiHeadClassifier(\n",
            "  (classifiers): ModuleDict(\n",
            "    (0): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "MultiHeadClassifier(\n",
            "  (classifiers): ModuleDict(\n",
            "    (0): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "    (1): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "MultiHeadClassifier(\n",
            "  (classifiers): ModuleDict(\n",
            "    (0): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "    (1): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "    (2): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "MultiHeadClassifier(\n",
            "  (classifiers): ModuleDict(\n",
            "    (0): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "    (1): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "    (2): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "    (3): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n",
            "MultiHeadClassifier(\n",
            "  (classifiers): ModuleDict(\n",
            "    (0): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "    (1): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "    (2): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "    (3): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "    (4): IncrementalClassifier(\n",
            "      (classifier): Linear(in_features=784, out_features=2, bias=True)\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from avalanche.benchmarks import SplitMNIST\n",
        "from avalanche.models import MultiHeadClassifier\n",
        "\n",
        "benchmark = SplitMNIST(5, shuffle=False, return_task_id=True, class_ids_from_zero_in_each_exp=True)\n",
        "model = MultiHeadClassifier(in_features=784)\n",
        "\n",
        "print(model)\n",
        "for exp in benchmark.train_stream:\n",
        "    model.adaptation(exp)\n",
        "    print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "XnVNha-Ve8Yk"
      },
      "source": [
        "When you use a `MultiHeadClassifier`, a new head is initialized whenever a new task is encountered. Avalanche strategies automatically recognize multi-task modules and provide task labels to them."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "lFkYuhwBe8Yk"
      },
      "source": [
        "### How to define a multi-task Module\n",
        "If you want to define a custom multi-task module you need to override two methods: `adaptation` (if needed), and `forward_single_task`. The `forward` method of the base class will split the mini-batch by task-id and provide single task mini-batches to `forward_single_task`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "id": "K-bpLTZ5e8Yk"
      },
      "outputs": [],
      "source": [
        "from avalanche.models import MultiTaskModule\n",
        "\n",
        "class CustomMTModule(MultiTaskModule):\n",
        "    def __init__(self, in_features, initial_out_features=2):\n",
        "        super().__init__()\n",
        "\n",
        "    def adaptation(self, dataset):\n",
        "        super().adaptation(dataset)\n",
        "        # your adaptation goes here\n",
        "\n",
        "    def forward_single_task(self, x, task_label):\n",
        "        # your forward goes here.\n",
        "        # task_label is a single integer\n",
        "        # the mini-batch is split by task-id inside the forward method.\n",
        "        pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "BmFCnlXFe8Yk"
      },
      "source": [
        "Alternatively, if you only want to convert a single-head model into a multi-head model, you can use the `as_multitask` wrapper, which converts the model for you."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "pycharm": {
          "name": "#%%\n"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MICmBRsPe8Yk",
        "outputId": "f7d5e1c9-a496-4285-e90c-e8db4b4ebf32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Dropout(p=0.25, inplace=False)\n",
            "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): Dropout(p=0.25, inplace=False)\n",
            "    (12): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): AdaptiveMaxPool2d(output_size=1)\n",
            "    (15): Dropout(p=0.25, inplace=False)\n",
            "  )\n",
            "  (classifier): Sequential(\n",
            "    (0): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ")\n",
            "MultiTaskDecorator(\n",
            "  (model): SimpleCNN(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): Dropout(p=0.25, inplace=False)\n",
            "      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (7): ReLU(inplace=True)\n",
            "      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (9): ReLU(inplace=True)\n",
            "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (11): Dropout(p=0.25, inplace=False)\n",
            "      (12): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (13): ReLU(inplace=True)\n",
            "      (14): AdaptiveMaxPool2d(output_size=1)\n",
            "      (15): Dropout(p=0.25, inplace=False)\n",
            "    )\n",
            "    (classifier): Sequential()\n",
            "  )\n",
            "  (classifier): MultiHeadClassifier(\n",
            "    (classifiers): ModuleDict(\n",
            "      (0): IncrementalClassifier(\n",
            "        (classifier): Linear(in_features=64, out_features=10, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from avalanche.models import as_multitask\n",
        "\n",
        "model = SimpleCNN()\n",
        "print(model)\n",
        "\n",
        "mt_model = as_multitask(model, 'classifier')\n",
        "print(mt_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ej7h2WCe8Yk"
      },
      "source": [
        "### Nested Dynamic Modules\n",
        "Whenever one or more dynamic modules are nested one inside the other, you must call the `recursive_adaptation` method, and if they are nested inside a normal pytorch module (non dynamic), you can call the `avalanche_model_adaptation` function. Avalanche strategies will by default adapt the models before training on each experience by calling `avalanche_model_adaptation`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 883
        },
        "id": "deM-MMfwe8Yk",
        "outputId": "286beea8-3016-4b34-f6da-275ba4d6ee07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultiTaskDecorator(\n",
            "  (model): SimpleCNN(\n",
            "    (features): Sequential(\n",
            "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (1): ReLU(inplace=True)\n",
            "      (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (3): ReLU(inplace=True)\n",
            "      (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (5): Dropout(p=0.25, inplace=False)\n",
            "      (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (7): ReLU(inplace=True)\n",
            "      (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "      (9): ReLU(inplace=True)\n",
            "      (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "      (11): Dropout(p=0.25, inplace=False)\n",
            "      (12): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (13): ReLU(inplace=True)\n",
            "      (14): AdaptiveMaxPool2d(output_size=1)\n",
            "      (15): Dropout(p=0.25, inplace=False)\n",
            "    )\n",
            "    (classifier): Sequential()\n",
            "  )\n",
            "  (classifier): MultiHeadClassifier(\n",
            "    (classifiers): ModuleDict(\n",
            "      (0): IncrementalClassifier(\n",
            "        (classifier): Linear(in_features=64, out_features=1, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'SimpleCNN' object has no attribute 'recursive_adaptation'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-93a0c312041c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mexp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbenchmark\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_stream\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mmt_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecursive_adaptation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmt_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/avalanche/models/helper_method.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m         \u001b[0;31m# If its a different attribute, return the one from the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1929\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1930\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1931\u001b[0;31m         raise AttributeError(\n\u001b[0m\u001b[1;32m   1932\u001b[0m             \u001b[0;34mf\"'{type(self).__name__}' object has no attribute '{name}'\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1933\u001b[0m         )\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'SimpleCNN' object has no attribute 'recursive_adaptation'"
          ]
        }
      ],
      "source": [
        "benchmark = SplitMNIST(5, shuffle=False, class_ids_from_zero_in_each_exp=True, return_task_id=True)\n",
        "\n",
        "model = SimpleCNN(num_classes=1)\n",
        "mt_model = as_multitask(model, 'classifier')\n",
        "\n",
        "print(mt_model)\n",
        "for exp in benchmark.train_stream:\n",
        "    mt_model.recursive_adaptation(exp)\n",
        "print(mt_model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4BkZwO11e8Yl",
        "outputId": "014cc07e-d3f3-43bc-f453-a9381ec61f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (features): Sequential(\n",
            "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): ReLU(inplace=True)\n",
            "    (2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (3): ReLU(inplace=True)\n",
            "    (4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (5): Dropout(p=0.25, inplace=False)\n",
            "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (7): ReLU(inplace=True)\n",
            "    (8): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (9): ReLU(inplace=True)\n",
            "    (10): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "    (11): Dropout(p=0.25, inplace=False)\n",
            "    (12): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "    (13): ReLU(inplace=True)\n",
            "    (14): AdaptiveMaxPool2d(output_size=1)\n",
            "    (15): Dropout(p=0.25, inplace=False)\n",
            "  )\n",
            "  (classifier): IncrementalClassifier(\n",
            "    (classifier): Linear(in_features=64, out_features=10, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "from avalanche.models.utils import avalanche_model_adaptation\n",
        "\n",
        "benchmark = SplitMNIST(5, shuffle=False, class_ids_from_zero_in_each_exp=False)\n",
        "\n",
        "model = SimpleCNN(num_classes=1)\n",
        "model.classifier = IncrementalClassifier(model.classifier[0].in_features, 1)\n",
        "\n",
        "for exp in benchmark.train_stream:\n",
        "    avalanche_model_adaptation(model, exp)\n",
        "\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "Y2Tgl5Dre8Yl"
      },
      "source": [
        "## ü§ù Run it on Google Colab\n",
        "\n",
        "You can run _this chapter_ and play with it on Google Colaboratory: [![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ContinualAI/avalanche/blob/master/notebooks/from-zero-to-hero-tutorial/02_models.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AM4KS4Oqe8Yl"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}